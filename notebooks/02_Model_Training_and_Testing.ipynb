{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ec6171",
   "metadata": {},
   "source": [
    "# Модель и обучение\n",
    "\n",
    "В этой части блокнота:\n",
    "- Определяется модель U-Net для сегментации\n",
    "- Реализуются функции метрик: DSC (Dice Similarity Coefficient) и IoU (Intersection over Union)\n",
    "- Выполняется обучение с логированием в TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a16b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Импорт конфигурации из первого блокнота (при условии, что блокнот 01 выполнен ранее)\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('run', '01_Configuration_and_Data_Preparation.ipynb')\n",
    "\n",
    "# Если вы не используете %run, можно просто скопировать нужные переменные:\n",
    "print(\"Используемые настройки:\")\n",
    "\n",
    "BASE_DIR = os.path.join( \"d:/\", \"NartovFatSegm\", \"Nartov_Fat_Segmentation\")\n",
    "print(\"IMAGE_DIR =\", os.path.join(BASE_DIR, \"data\", \"cropped_images\"))\n",
    "print(\"MASK_DIR =\", os.path.join(BASE_DIR, \"data\", \"cropped_masks\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели U-Net с использованием библиотеки segmentation_models_pytorch\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def create_unet_model(in_channels=1, classes=1, encoder_name=\"efficientnet-b2\", encoder_weights=\"imagenet\"):\n",
    "    \"\"\"\n",
    "    Создаёт модель U-Net для сегментации.\n",
    "    \n",
    "    Возвращает:\n",
    "        Модель U-Net.\n",
    "    \"\"\"\n",
    "    model = smp.Unet(\n",
    "        encoder_name=encoder_name,\n",
    "        encoder_weights=encoder_weights,\n",
    "        in_channels=in_channels,\n",
    "        classes=classes,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_unet_model()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Модель создана и переведена на\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccccf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функций метрик: Dice (DSC) и IoU.\n",
    "\n",
    "\n",
    "def dice_coefficient(pred, target, threshold=0.5, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Вычисляет Dice Similarity Coefficient (DSC).\n",
    "\n",
    "    Dice = 2 * (|pred ∩ target|) / (|pred| + |target|)\n",
    "    \n",
    "    Возвращает среднее значение DSC по батчу.\n",
    "    \"\"\"\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = (pred > threshold).float()\n",
    "    # Вычисление пересечения и суммы\n",
    "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "    union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3))\n",
    "    dice = (2. * intersection + eps) / (union + eps)\n",
    "    return dice.mean().item()\n",
    "\n",
    "def iou_metric(pred, target, threshold=0.5, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Вычисляет метрику Intersection over Union (IoU).\n",
    "\n",
    "    IoU = (|pred ∩ target|) / (|pred ∪ target|)\n",
    "    \n",
    "    Возвращает среднее значение IoU по батчу.\n",
    "    \"\"\"\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred = (pred > threshold).float()\n",
    "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "    union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) - intersection\n",
    "    iou = (intersection + eps) / (union + eps)\n",
    "    return iou.mean().item()\n",
    "\n",
    "print(\"Функции для Dice и IoU определены\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем полный датасет\n",
    "full_dataset = UltrasoundSegmentationDataset(\n",
    "    images_dir=os.path.join(BASE_DIR, \"data\", \"cropped_images\"),\n",
    "    masks_dir=os.path.join(BASE_DIR, \"data\", \"cropped_masks\"),\n",
    "    transform=TRAIN_TRANSFORMS  # для обучения\n",
    ")\n",
    "\n",
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=RANDOM_STATE)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=RANDOM_STATE)\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "# Для валидации используем трансформации, исключающие случайные изменения\n",
    "from copy import deepcopy\n",
    "val_dataset = Subset(\n",
    "    UltrasoundSegmentationDataset(\n",
    "        images_dir=os.path.join(os.getcwd(), \"data\", \"cropped_images\"),\n",
    "        masks_dir=os.path.join(os.getcwd(), \"data\", \"cropped_masks\"),\n",
    "        transform=VAL_TRANSFORMS\n",
    "    ),\n",
    "    val_indices\n",
    ")\n",
    "\n",
    "# DataLoader-ы (можно задать в ячейке)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(\"Датасеты и DataLoader-ы подготовлены\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeccfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Определяем цикл обучения.\n",
    "Логируются метрики: Loss, Dice, IoU.\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Функции потерь\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "dice_loss_fn = smp.losses.DiceLoss(mode=\"binary\")\n",
    "def combined_loss_fn(outputs, masks):\n",
    "    return bce_loss(outputs, masks) + dice_loss_fn(outputs, masks)\n",
    "\n",
    "writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    dice_train_sum = 0.0\n",
    "    iou_train_sum = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device).float()\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = combined_loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        dice_train_sum += dice_coefficient(outputs, masks) * images.size(0)\n",
    "        iou_train_sum += iou_metric(outputs, masks) * images.size(0)\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_train_dice = dice_train_sum / len(train_loader.dataset)\n",
    "    epoch_train_iou = iou_train_sum / len(train_loader.dataset)\n",
    "\n",
    "    writer.add_scalar(\"Train/Loss\", epoch_train_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Dice\", epoch_train_dice, epoch)\n",
    "    writer.add_scalar(\"Train/IoU\", epoch_train_iou, epoch)\n",
    "\n",
    "    # Валидиация\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    dice_val_sum = 0.0\n",
    "    iou_val_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device).float()\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = combined_loss_fn(outputs, masks)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            dice_val_sum += dice_coefficient(outputs, masks) * images.size(0)\n",
    "            iou_val_sum += iou_metric(outputs, masks) * images.size(0)\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "    epoch_val_dice = dice_val_sum / len(val_loader.dataset)\n",
    "    epoch_val_iou = iou_val_sum / len(val_loader.dataset)\n",
    "\n",
    "    writer.add_scalar(\"Validation/Loss\", epoch_val_loss, epoch)\n",
    "    writer.add_scalar(\"Validation/Dice\", epoch_val_dice, epoch)\n",
    "    writer.add_scalar(\"Validation/IoU\", epoch_val_iou, epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]: \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f} | Dice: {epoch_train_dice:.4f} | IoU: {epoch_train_iou:.4f} || \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f} | Dice: {epoch_val_dice:.4f} | IoU: {epoch_val_iou:.4f}\")\n",
    "    \n",
    "    # Сохранение лучшей модели\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"Сохранена лучшая модель на эпохе {epoch+1}\")\n",
    "\n",
    "writer.close()\n",
    "print(\"Обучение завершено\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6224d",
   "metadata": {},
   "source": [
    "# Оценка модели и визуализация результатов\n",
    "\n",
    "В этой части блокнота:\n",
    "- Загружается сохранённая модель\n",
    "- Выполняется тестирование на тестовой выборке\n",
    "- Визуализируются результаты (входное изображение, истинная маска и предсказание)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем полный датасет с трансформациями для валидации/теста\n",
    "full_dataset = UltrasoundSegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASK_DIR,\n",
    "    transform=VAL_TRANSFORMS\n",
    ")\n",
    "\n",
    "# Разбивка для теста (при условии, что индексы совпадают с предыдущим блокнотом)\n",
    "indices = list(range(len(full_dataset)))\n",
    "_, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "_, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Переиспользуем те же настройки\n",
    "IMAGE_DIR = os.path.join(os.getcwd(), \"data\", \"cropped_images\")\n",
    "MASK_DIR = os.path.join(os.getcwd(), \"data\", \"cropped_masks\")\n",
    "\n",
    "\n",
    "# Загружаем полный датасет с трансформациями для валидации/теста\n",
    "full_dataset = UltrasoundSegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASK_DIR,\n",
    "    transform=VAL_TRANSFORMS\n",
    ")\n",
    "\n",
    "# Разбивка для теста (при условии, что индексы совпадают с предыдущим блокнотом)\n",
    "indices = list(range(len(full_dataset)))\n",
    "_, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "_, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Создаём модель и загружаем сохранённые веса\n",
    "model = create_unet_model()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "model.eval()\n",
    "print(\"Модель загружена для тестирования\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "dice_test_sum = 0.0\n",
    "iou_test_sum = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "        if images.ndim == 3:\n",
    "            images = images.unsqueeze(1)\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = combined_loss_fn(outputs, masks)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        dice_test_sum += dice_coefficient(outputs, masks) * images.size(0)\n",
    "        iou_test_sum += iou_metric(outputs, masks) * images.size(0)\n",
    "\n",
    "epoch_test_loss = test_loss / len(test_loader.dataset)\n",
    "epoch_test_dice = dice_test_sum / len(test_loader.dataset)\n",
    "epoch_test_iou = iou_test_sum / len(test_loader.dataset)\n",
    "\n",
    "print(\"Тестовые метрики:\")\n",
    "print(f\"Test Loss: {epoch_test_loss:.4f}\")\n",
    "print(f\"Test Dice: {epoch_test_dice:.4f}\")\n",
    "print(f\"Test IoU: {epoch_test_iou:.4f}\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Получаем один батч для визуализации\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).float()\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.unsqueeze(1)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        preds = (preds > 0.5).float()\n",
    "        break  # достаточно одного батча\n",
    "\n",
    "# Перенос на CPU\n",
    "images = images.cpu().numpy()\n",
    "masks = masks.cpu().numpy()\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "n = min(7, images.shape[0])\n",
    "for i in range(n):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[i].squeeze(0), cmap=\"gray\")\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(masks[i].squeeze(0), cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(preds[i].squeeze(0), cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UltraSam)",
   "language": "python",
   "name": "ultrasam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
